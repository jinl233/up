# 存储器概述
- 现代计算机**以存储器为中心**，它是计算机中**存放指令和数据**的主要部件   
  - 存储器的容量越大，能存储的信息越多  
  - 提高存储系统的访问速度，是提高计算机处理信息速度的重要措施  
- 因此，开发具有**大容量**、**高速度**和**低成本**的**存储系统**是计算机技术发展的关键目标之一  


## 存储器分类
![图 2](../../images/330a9fb3fc308cf5b57780cd7397ef5da3f1474ea4ff81669eca45c78b46b5c3.png)  


| 存储器类型             | 特点                                       | 具体种类                                                                                                     |
| ---------------------- | ------------------------------------------ | ------------------------------------------------------------------------------------------------------------ |
| $RAM$                  | 数据读写速度快，断电后数据丢失             | $SRAM$：高速，耗电大，成本高（用于缓存）<br> $DRAM$：速度慢，需刷新，成本低（用于主存）                      |
| $ROM$                  | 数据只读，断电后数据不丢失                 | $PROM$：一次性可编程<br> $EPROM$：可擦除，需紫外线<br> $EEPROM$：电可擦除，可多次编程                        |
| $Flash\quad    Memory$ | 电可擦除，多次编程，断电后数据不丢失       | $NAND\quad    Flash$：适合大容量存储（ $U$ 盘、$SSD$）<br> $NOR\quad    Flash$：随机访问快（固件）           |
| $Cache\quad    Memory$ | CPU 和主存之间的小容量快速存储器           | $L1\    Cache$：速度最快，容量小<br> $L2\    Cache$：容量大于 $L1$ ，略慢<br> $L3\    Cache$：共享，容量更大 |
| 虚拟存储器             | 通过硬盘扩展内存容量，支持多任务管理       | 使用页表和页面置换算法（如 $LRU$、$FIFO$）                                                                   |
| $CMOS\quad    Memory$  | 依赖电池供电，用于保存系统配置参数         | 主要用于 $BIOS$ 设置等                                                                                       |
| 磁性存储器             | 数据通过磁性介质存储，速度较慢             | $HDD$：数据存储密度高<br> 磁带：顺序访问，大批量备份<br>$MRAM$：高速，断电保持数据                           |
| 光学存储器             | 数据通过激光读取和写入                     | $CD / DVD / Blu-ray$：用于数据分发和备份                                                                     |
| 量子存储器             | 利用量子态保存信息，潜在超高密度和超快速度 | 目前在量子计算中研究和实验                                                                                   |

#### 存储介质


##### 磁存储器

- 以磁性材料作为存储介质  
- 利用磁化单元的不同磁化方向来存储数据0和1  
- 主要包括磁芯、磁盘、磁带存储器  
- 磁盘、磁带中都包含有机械装置，因此体积大、存取速度慢、但其单位容量成本最低  

##### 光存储器

- 利用介质的光学特性读出数据  
	- 例如CD-ROM、DVD-ROM都以刻痕的形式将数据存储在盘面上，用激光束照射盘面，靠盘面的不同反射率来读出信息  
- 光盘存储器成本低廉、适用于电子出版物的发行  

##### 半导体存储器

- 用半导体器件组成的存储器  
- 存取速度快、体积小、性能可靠，但单位容量成本相对较高  

#### 存取方式


##### 顺序存储器

- 存储单元中的内容**只能依地址顺序访问**  
	- **存取速度与存储单元的位置有关**  
- 磁带存储器就是典型的顺序存储器  

##### 随机存储器

- **可按给定的任何一个存储单元的地址对其内容进行存取**  
	- **存取速度与存储单元的位置无关**  
- 早期的磁芯存储器和当前广泛使用的半导体存储器都是随机存储器  

##### 直接存储器

- **不必经过顺序搜索就能在存储器中直接存取信息**  
	- **兼有随机存储器和顺序存储器的访问特性**  
- 典型的如磁盘存储器。由于磁盘存在机械寻道和旋转延迟，因此数据访问时间和磁头与目标扇区的距离有关  

#### 可改写性

##### 读写存储器

- 既能读出也能写入信息

##### 只读存储器

- **存储的内容不允许被改变，只能读出**  
- 常见的有光盘存储器  
- 还有半导体只读存储器，信息只能读出、**不能随意写入**   
主要用来存放一些不需要修改的程序(例如B1OS)和常量  

#### 可保存性

##### 易失性存储器

- 断电后所保存的信息会丢失

##### 非易失性存储器

- 断电后所保存的信息不丢失

#### 功能和存取速度

![图 1](../../images/e70415f9261270a81fbaf7458d8e10868b1bdea9266f201adb7d21b1e74249de.png)  

##### 寄存器存储器

- CPU内部的多个寄存器（例如MAR、MDR、ACC、MQ等）   
- 用于存放地址、数据以及运算的中间结果  
- **速度与CPU匹配，容量极小**  

##### 高速缓冲存储器

- 寄存器与主存之间的一个**高速小容量**存储器  
- 用于**缓冲CPU与主存之间的性能差异**，提高存储系统的访问速度  
- 存放内容一般是即将或经常要使用的指令和数据  

##### 主存储器

- 用于存放指令和数据  
CPU可以通过主存地址**随机**地读写主存  
- **存取速度低于高速缓存，但一般高于辅存**  
- **容量远大于高速缓存，但一般远小于辅存**  


##### 辅助存储器

- 存放当前暂不参与运行的程序和数据，以及一些需要长期保存的信息   
- **容量很大，但存取速度相对较低**    


## 存储器性能指标和存储系统层次结构

### 存储容量

- 存储容量是指存储器可以存储的二进制信息的总量

![图 3](../../images/134ed2ba9148b1e74bd71721b2e416fe7522813c38d4c160a101de0f90fea563.png)  

### 存取速度

##### 存取时间

- 启动一次存储器操作到该操作完成所经历的时间 **(可能不同)**  
	- 读出时间  
	- 写入时间  

##### 存取周期

- 连续两次访问存储器操作（读操作或写操作）之间所需要的最短时间间隔  
- 对于主存，存取周期除包括存取时间外，还包括存储器状态的稳定恢复时间，因此存取周期略大于存取时间  

![图 4](../../images/3ed06ef8af8c44bf7ee3aaf42f98c31f51d852a2151a97039f98ae25ea70b921.png)  

##### 存储器带宽

- 单位时间内存储器所能传输的信息量(单位：b/s或B/s)
- 它是衡量数据传输速率的重要指标，与一次传输的数据位的多少和存取时间的长短有关
	- 一般而言，数据位宽越大、存取时间越短，则存储器带宽越高

### 存储系统层次结构

![图 5](../../images/8638d092b992e6f8b6fbb6911457533f5e662f58c0589162e3f597a58aa6b745.png)  

- **上层存储器可为下层存储器做缓冲**，将最经常使用的数据的副本调度到上层，使得CPU只需要访问上层的快速小容量存储器即可获得大部分数据。可以有**效提高存储系统的访问速度，缓解CPU与主存（内存）、主存(内存)与辅存（外存）的性能差异**    
- 另外，**使用大容量辅存**（外存），**缓解了主存（内存）容量不足的问题**  

> [! todo] 基于这种层次结构，就可构建出满足应用需求的存储容量大、存取速度快、成本低的存储系统  

## 主存的基本结构

- 主存是机器指令直接操作的存储器，需要基于**主存地址**对其进行**随机访问**
  ![图 8](../../images/c446d2cf5634ba62d00018f1123ba537e250c92d5ad56e2b940e9dca609e9c10.png)  
 

![图 7](../../images/1640022d49e09d25c2638680b1eb1e6950fa425ac0b91c2a90833ad6cb76434e.png)  

- 输入地址、获取数据
  ![图 9](../../images/af184b9a2feb25495a967915015f9488665752fb60e96c9417af22bd8c21f067.png)  

- 输入数据、选择地址、写入
  ![图 10](../../images/e2a2444b55ef96bd5d6f1ee4c2d804c56161cccfcb7038d8e023feae4d33c8d7.png)  

> [! todo] 随着硬件技术的发展内存都制成大规模集成电路芯片，而将MAR和MDR集成到了CPU中

## 用于地址译码的译码结构

### 单译码结构

- 若主存的存储体包含64个存储单元，每个存储单元只能存储1个二进制位，请给出只使用一个译码器就能寻址这64个存储单元的方案（即译码器的地址输入线和译码输出线各需要几条）  

> [! question] 若存储体包含64k个存储单元，则译码器的地址输入线和译码输出线各需要几条？
>译码输出线：$64k$ 条
>地址输入线：$16$ 条 ($2^{16} =64 k$)

- 随着存储容量（存储体中存储单元的数量）的增大，译码输出线也随之增多，这样，译码电路的开销就不容忽视，过多的译码输出线也会占用较多的晶圆面积，为生产制造带来困难

- 因此，**单译码结构只适用于容量很小的存储芯片**（例如容量在几百个存储单元以内的存储芯片）

### 双译码结构

![图 11](../../images/40df8bc6eae8b2d9d9ac5f072791da7c35fdf85a77b4aec93c2e027ead600095.png)  

- **在大容量存储器中普遍采用双译码结构**

## 主存中数据的存放

### 机器字长与存储字长的区别

- 机器字长   
	**CPU一次能够处理**的二进制数据的**位数**  
- 存储字长  
	主存中的**一个存储单元**所能存储的二进制**位数**  
> **存储字长与机器字长不一定相同**，例如机器字长为32位的计算机，所采用的存储字长可以是16位、32位或64位

### 地址访问模式

- 主存通常按字节进行编址，而存储字长（主存中的一个存储单元所能存储的二进制位数）是字节的2的整数次幂倍(例如1字节，2字节，4字节等)
- 以机器字长为32位的计算机为例，对主存的访问既可以按字节访问，也可以按16位半字访问，还可以按32位字访问。因此，可将主存地址分为：
	- 字节地址
	- 半字地址
	- 字地址

![图 12](../../images/4ff8e26b5cf127ab03bee180b99de1927d34a7342cae474ba8cce21b7dcbbe87.png)  

###### Intel x86汇编语言访问不同存储单元举例
> (假设数据段寄存器DS的值为0)

``` nasm
MOV AL,[0x4]
	;将地址0x4开始的1字节存储单元的内容送入8位寄存器AL,结果为[AL]=0x00
MOV AX,[0x4]
	;将地址0x4开始的2字节存储单元的内容送入16位寄存器AX,结果为[AX]=0xEF00
MOV EAX,[0x4]
	;将地址0x4开始的4字节存储单元的内容送入32位寄存器EAX,结果为[EAX]=0xABCDEF00
```

- 从上述程序可以看出，不**同的地址访问模式**（字节访问、半字访问、字访问）**所使用的主存地址实际上都是字节地址**，CPU在执行指令的时候可以将字节地址的低2位用于访问控制：  
	- 采用字节访问摸式，字节地址的低2位用于选择字存储单元中的哪一个字节  
	- 采用半字访问摸式，字节地址的倒数第2位用于选存储单元中的哪个半字  

### 大端和小端方式
![图 13](../../images/83a3468bbef38a7fc28faba8bc12697cd538ef12fa00a1d608ddd04a816fca97.png)  

###### 小端
- 将数据的低字节保存在主存的低地址中，而数据的高字节保存在主存的高地址中  
- 这样可以将主存地址的高低与数据的位权有效地结合起来，高地址存储的数据部分的权值高，低地址存储的数据部分的权值低，符合逻辑  
- Intel x86、IA64、RISC-V等处理器采用小端方式  
###### 大端
- 将数据的高字节保存在主存的低地址中，而数据的低字节保存在主存的高地址中  
- 符合人类的正常思维  
- PowerPC处理器采用大端方式：ARM、MIPS等处理器同时支持大端方式和小端方式  

> [! tip]
> 1. 上述两种方式并没有绝对的优劣之分，它们在不同的处理器架构和应用场景中都有各自的适用性和优势  
> 2. 除处理器外，大小端方式还涉及外部设备设计、网络数据传输、音视频文件保存等  
> 3. 小端与大端方式的区别不仅存在于处理器的寄存器、存储器中，在指令集、系统总线等各个层次中也可能存在差别  

### 数据的边界对齐
- **主存空间**通常**按字节**进行**编址**   
- 高级语言中**不同数据类型的变量**所包含的**字节数量可能不同**  
	- 编译器在为这些变量分配主存空间时，理论上可以从主存空间的**任何一个字节地址开始**  
	- 当一个多字节变量被编译器**分布在不同的字存储单元中**时，访问该变量就需要**多个存取周期**  
	- 为了**提高数据访问效率**，应该要考虑数据变量、数据结构在**主存空间中的边界对齐问题**  

##### 假设存储字长为32位，为C语言不同数据类型的变量分配主存空间
> ![图 14](../../images/ae125d7f934df73d77a08f44c5584de13f70acb73bb4e8d3bdd4cc43d869f886.png)  

###### 数据的边界未对齐
![图 15](../../images/f61bd463be8e5bbc7c0a366425367b6432acb5620293b248adbed4aea098ce59.png)  

- 对存储空间的利用率最高
- 存在访问性能问题，例如：
	- 变量c的8个字节分布在3个存储单元中（访问该变量需要3个存取周期）
	- 变量的2个字节分布在2个存储单元中（访问该变量需要2个存取周期）



###### 数据的边界对齐
![图 16](../../images/bdb1c2c3fabce2ce2024001cd2e2aae4bc6047f70fb5d17d15bc0b6cb9a42799.png)  

- 有效提升了访问性能，例如：
	- 变量c的8个字节分布在2个存储单元中(访问该变量需要2个存取周期)
	- 变量的2个字节分布在1个存储单元中（访问该变量需要1个存取周期）
- 造成存储空间的浪费

##### 边界对齐的规则

- 字节数据不存在边界对齐问题（因为主存空间就是按字节编址的）  
- 半字(2字节)数据的起始字节地址的最低1位为0(即地址是2的整数倍)  
- 单字(4字节)数据的起始字节地址的最低2位为00(即地址是4的整数倍)  
- 双字(8字节)数据的起始字节地址的最低3位为000(即地址是8的整数倍)  

![图 17](../../images/8297e5f126fed8bab28ff22e764f1f3514b1483bdeddd50b811b4fdb7b8bc6a6.png)  



# 静态随机存取存储器SRAM
- 随机存取存储器RAM的一种 
- 所谓“静态”，是指这种RAM只要保持通电，其内部所存储的数据就可以保持不变，而不需要进行周期性地刷新。相比之下，动态随机存取存储器DRAM则需要  
- 一旦断电，SRAM和DRAM内部存储的数据还是会消失的，也就是说SRAM和DRAM属于易失性存储器这与属于非易失性存储器的只读存储器ROM(Read-OnlyMemory)是不同的    
## 存储元
> 存储元(存储1个二进制位的单元)一般采用多个金属-氧化物半导体场效应晶体管MOSFET来构建，MOSFET常简称为MOS管

##### mos管
![图 18](../../images/5b653c67f9e1a7c18c898020727abf5a1eea62f5133afc3a4d736ae8ca3de61f.png)  

##### 存储元电路
![图 19](../../images/2b94d3001bca196c9d47e9f9516f0bea0f4ef63d5825070b29c24cbc1bfaf489.png)  

##### 上电后初始状态
> (行选通X和列选通Y都为无效信号)

![图 20](../../images/b61ec78db2597da8f5eb9f2080f05516ad6e19d58d6c6776fd03eaeafde003ae.png)  

- 实际上，a点和b点上升到高电平的时间不可能完全相同  
- 本例中假设a点首先上升到高电平  
- 此时，α点高电平(1)和b点低电平(0)，形成一个稳定状态，可用这个状态表示数据1  
- 若最初b点先上升到高电平，则会形成另一个稳定状态，即a点低电平(0)和b点高电平(1)，该状态表示数据0  
- 综上所述，上电后初始状态随机（即存储元的存储内容随机）
##### 读操作
> (行选通X和列选通Y都为有效信号)

![图 24](../../images/3f472cb5f04914ce530806a18c8e10980a696a8342132ef923a5e0adaff06b72.png)  
  
- 读操作不会破坏原有数据  

##### 写操作
> (行选通X和列选通Y都为有效信号)

![图 22](../../images/c7a59bc0497103ff26ccedf0d28d25c39be21d7df1570756320a5fec8e3be030.png)  


##### 信息的保持
> (行选通X和列选通Y都为无效信号)

![图 23](../../images/aede553e64da45e06343a2aa29ba2bf275295edde3f6cdc263193b126f2df680.png)  

#### 总结
- **上电后的初始状态随机**（即存储元的存储内容随机）  
- **读操作不会破坏原有数据**  
- 只要不断电，信息一直保存，不需要刷新  
- 电源$V_{cc}$通过负载管 $T_3$ 、$T_4$ 不断为工作管 $T_1$ 或 $T_2$ 提供电流，以保存信息，因此 **功耗大**   
- 使用**晶体管的数量多**，占用晶圆面积大，成本高，价格昂贵，因而**不适合用于**更高存储密度且低成本的应用，例如**PC的内存**  
- **速度快**，常用于微处理器的cache  

## 存储元扩展和存储阵列扩展
- 电路符号化
![图 25](../../images/4cefd304b578c000126b78ded9729eb3d771ecfca329e9a4cbddef28cfdc37b1.png)  

#### 存储元扩展
![图 26](../../images/2b4e70948ec2d7e33fae9f92857c756fc3bb2d353fe1c9624f9532b4593ae14a.png)  

> [!SUCCESS] 存储阵列
> 行选通线:$X_0 \sim X_{n-1},共n条$  
> 列选通线:$Y_0 \sim Y_{n-1},共n条$  
> 选通线合计:$2n$条  
> 存储元:$n\times n=n^2$个  


- 同一时刻，只能有一条行选通线和一条列选通线输出有效信号，因此只能有一个存储元被选中，也就是一次只能访问一位数据

#### 存储阵列扩展
> 将多个存储阵列的行选通线并联、列选通线并联

![图 27](../../images/e9f7d03db5ae0a3cde8e4cc2cb113cd49fc7b66b56f3d5a1e7b82f24b6435473.png)  

- 存储字长为4位包含$n^2$个存储字

## 存储器结构及其芯片实例
![图 29](../../images/bcef43600b38f61670c9937798a7ba4d891d7822e25de4a30d2ef5afec1eca20.png)  

> 存储器
> - 每个 $64\times 64$ 存储阵列(即64行64列)包含 $64\times 64=4096$ 个存储元(每个存储元存储 $1$ 位二进制数)
> - 行选通线：$X_0 \sim X_{63}$，共64条
> - 列选通线：$Y_0 \sim Y_{63}$，共64条
> - 存储字长：$4$ 位（一次可存取的位数）
> - 存储容量：$4096位/片\times 4片=4096 b\times 4\div 8=2kB$

> 驱动器
> - 行译码器的每个译码输出信号线都要同时驱动**这一行上所有存储元**的 $T_5$、$T_6$ 两个门控管  
> - 4片存储阵列并发，每个行译码输出信号线要驱动 $2\times 64\times 4=512$ 个门控管，负载大  
> - 列译码器的每个译码输出信号线都要同时驱动**这一列上所有存储元**共享的$T_7$、$T_8$ 两个门控管  
> - 4片存储阵列并发，每个列译码输出信号线要驱动 $2\times 4=8$ 个门控管，负载较大  

![图 30](../../images/deb277d4598869135c9e451a92e605dccd53a034999b46cc8152c06ce515e147.png)  


# 动态随机存取存储器DRAM

## 存储元及其扩展

#### 存储元
> [!TIP] 设法尽量**减少MOS管**，通过**引入存储电容**暂存电荷的方式来保存数据</p>目前在内存中较为常见的结构是 **单MOS管** 和**电容**构成的DRAM存储元

- 电容**C充满电的状态**，表示二进制1
![图 31](../../images/1741c94b82fea5ebfa1ab41e3f5559a6aa53c34a3d95c061f38827d7b9f8505f.png)  
- 电容**C完全没电的状态**， 表示二进制0
![图 32](../../images/f6e2d1fab581dff926e26ea9809f635ddf2201dd6c000663953de18efb4a8e61.png)  
- 上述电容C放电过程，可看作是对存储元的读操作，可以发现读操作会导致原本存储的1读取后变成0。为避免读操作导致的数据丢失，数据1读出后应将数据1重新写入，称为**数据恢复**  
- MOS管不可能完美关断，电容C上的电荷会逐渐泄露，数据1只能保存较短的时间。为避免数据丢失，必须定期采用类似读操作的方式对电容C补充电荷，称为**刷新**， 这也是动态RAM(DRAM)得名的原因  
![图 33](../../images/ce01039ff98740017a206fa6781e7dc54acdbb58375943dd18f3e8bd8b4afcd2.png)  

#### 存储元扩展
![图 34](../../images/7a5d8ff1ed2c623a597252338fac57c991e6b75592fd37fd07aa1ed58bcae717.png)  
- 为了**读取**一行中某个存储元的信息，**却破坏了这一行中所有存储元的信息**    
- 因此，**每次读操作过后，必须立即进行写操作**  
- 灵敏读出/恢复放大器会根据锁存的值，将各条列线拉高到 $DRAM$ 的工作电压 $Vcc$ ，或拉低到 $GND$ ，以恢复各存储元中电容的原本状态（即原本存储的信息）  

| 步骤  | $DRAM$ 的**读**操作流程 | $DRAM$ 的**写**操作流程 |
| :---: | :---------------------: | :---------------------: |
|   1   |       预充电操作        |       预充电操作        |
|   2   |        访问操作         |        访问操作         |
|   3   |        信号检测         |        信号检测         |
|   4   |        数据恢复         |        数据恢复         |
|   5   |        数据输出         |        数据输入         |



#### DRAM与SRAM的对比


|        对比项目        |       动态随机存取存储器DRAM        |          静态随机存取存储器SRAM          |
| :--------------------: | :---------------------------------: | :--------------------------------------: |
|    构成存储元的元件    |    $1$ 个 $MOS$ 管和 $1$ 个电容     |             $6$ 个 $MOS$ 管              |
| 读操作后需要“数据恢复” | 需要 （读操作会改变原本存储的信息） |   不需要（读操作不改变原本存储的信息）   |
|     需要动态“刷新”     |      需要 （电容的电荷会泄露）      | 不需要（功耗管和工作管负责保持存储状态） |
|      送行/列地址       | 分两次送（地址线复用，减少地址线）  |                  同时送                  |
|        运行速度        |                较慢                 |                    快                    |
|         集成度         |                 高                  |                    低                    |
|         发热量         |                 小                  |                    大                    |
|        存储成本        |                 低                  |                    高                    |
|        可保存性        |   易失性存储器 （断电后信息丢失）   |    易失性存储器 号 （断电后信息丢失）    |
|        常用应用        |                主存                 |                 $cache$                  |
|        存储信息        |       电容，充电是1，否则为0        |        双稳态触发器，分为0态和1态        |


## 动态刷新

```mermaid
flowchart LR
    subgraph one
        direction LR
    id1(基本概念)-->id3(刷新周期);
    id1(基本概念)-->id4(刷新存储元的数量);
    id1(基本概念)-->id5(刷新与读操作的区别);
    end
    subgraph two
        direction LR
    id2(刷新方式)-->id6(集中刷新);
    id2(刷新方式)-->id7(分散刷新);
    id2(刷新方式)-->id8(异步刷新);
    end
    one --> two
 style id2 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:4px,color:#000,stroke-dasharray: 5 5
 style id1 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:4px,color:#000,stroke-dasharray: 5 5
 style id3 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:1px
 style id4 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:1px
 style id5 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:1px
 style id6 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:1px
 style id7 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:1px
 style id8 fill:#eaf5f2,stroke:#0dbfb6,stroke-width:1px
```
#### 基本概念
##### 刷新周期

- 从数据存入DRAM开始，到数据丢失之前为止的这段时间，称为**最大刷新周期**   
  - 采用不同材料以及不同生产工艺生产的 $DRAM$ ，其最大刷新周期可能不同，常见的有 $2ms$ 、 $4ms$ 、 $8ms$ 等   
- 而**刷新周期**是 $DRAM$ 实际完成两次**完整刷新**之间的时间间隔   
  - 刷新周期 ≤ 最大刷新周期   

##### 刷新存储元的数量  
- $DRAM$ **按行进行**刷新  
  - 为了**缩短刷新周期**，可**减少**存储阵列的**行数**，增加列数  
- 刷新操作由内存控制器负责  

##### 刷新与读操作的区别
- 尽管读操作也具有刷新功能，但读操作与刷新操作又有所不同，**刷新操作只需要给出行地址**，而不需要给出列地址

#### 刷新方式
> $DRAM$ 在刷新时，是不能响应 $CPU$ 的访问的，因此 $CPU$ 对 $DRAM$ 进行访问与内存控制器对 $DRAM$ 进行刷新操作就存在内存争用问题

> [!todo] 假设 $DRAM$ 存储体的结构为 $128$ 行 $×128$ 列，存取周期为 $0.5μs$ ，刷新周期为 $2ms$   
> **刷新操作与读操作类似**，存取周期=刷新一行所需的时间  
> **刷新周期**为 $2ms$ ,在 $2ms$ 内要**完成所有128行的刷新**   
> 将 $2ms(2000μs)$ 划分成 $4000$ 个 $0.5μs$ 长的时隙，在这些时隙中选出 $128$ 个时隙每个时隙刷新一行即可

##### 集中刷新

![图 35](../../images/b8907c89a8bc9f68b036fdb5e677ac5ae48f95f02a872e134aeb0b2e7f272116.png)  

- 读写操作期间不受刷新操作的影响，因此这段时间的访问**速度比较快**  
- 但是，在集中刷新的这128个时隙中，CPU长时间不能访问DRAM，这段时间称为 为 **“死区"时间**  
	- 存储体包含的**行数越多，“死区”时间就越长**  

##### 分散刷新
![图 36](../../images/03fbec8afece52488fed665cc766e919f8e9034641dd5fb0841e712b36250327.png)  

- 相当于将存取周期加上刷新$1$行的时长作为新的存取周期，因此**不存在“死区”时间**。但是，这种方式**刷新过于频繁**（在$2ms$所包含的$4000$个时隙中，有$2000$个时隙用于刷新，每个时隙刷新$1$行，共刷新$2000$行，每刷新$128$行，就相当于把存储体完整地刷新了$1$遍，因此在$2ms$内进行了约$15$次完整的存储体刷新），**严重影响了系统的速度**  
- 不适合应用于高速存储器  


##### 异步刷新
![图 37](../../images/ba501ff0e1ddcffefbf1a0684ae087648923e49f736aad67d6f431c798b96101.png)  

- 既充分利用了$2ms$时间，又保持系统高速特性。该方式缩短了死区时间($128$个时隙缩短为$1$个时隙)，该方式相对上述两种效率更高，更为常用

## 存储器芯片实例和DRAM发展
#### 芯片示例
![图 38](../../images/674d61420ec50554527f7241ca838e0cb2d91fe6a80a40bb4696bc30f897e883.png)  

#### 发展
![图 39](../../images/873b21a552bc1c3ff546e3a4e9b23523c84419a992f552a607fbbd2116374142.png)  

- **异步DRAM的读写操作与CPU的时钟周期无关**，在进行读写操作时可能会有更多的等待周期，导致性能上的损失，特别是在CPU的时钟频率很高的情况下   
- **同步DRAM的读写操作与CPU的时钟周期同步**，内存控制器可以在时钟信号的特定边缘（上升沿或下降沿）触发数据传输  

###### SDRAM 

![图 40](../../images/9c0a72b1e16d41c7b440bfb34543c8d1a777d1e51d27b96aa49a93d8bfe7e605.png)  

- $t_{RCD}(RAS\   to\   CAS\    Delay)$ :从行地址选通 $(RAS)$ 到列地址选通 $(CAS)$ 之间的延迟时间  
- $CL(CAS\    Latency)$ :从列地址选通 $(CAS)$ 到开始数据传输的延迟时间  
- $SDRAM$ 自带时钟信号，能与系**统总线频率同步**  
- $SDRAM$ 可以**突发 $(Burst)$ 传输**：第一个列数据就绪后，每经历一个时钟周期就可得到一个数据，有效减少了数据传输的时间延迟  
  - 通常 $SDRAM$ 包含有模式寄存器，可配置**突发传输的长度BL** $(Burst\    Length)$ ，例如 $1、2、4、8$ 以及整行字。该长度是同步地向系统总线上发送数据的存储单元的个数  

> [! danger] *传统DRAM没有突发传输模式* ，每访问一个数据，就要经历行地址、列地址、访问数据的过程  </p>*传统DRAM属于异步DRAM* ,其读写操作与CPU的时钟周期无关，在进行读写操作时可能会有更多的等待周期，导致性能的损失，特别是在CPU的时钟频率很高的情况下  

- 在 $SDRAM$ 之后出现的 **DDR** SDRAM $(Double Data Rate SDRAM)$，其内部采用了2路预取机制，第一个数据输出后，每个时钟周期可传输两次数据，即在**时钟周期的上升沿和下降沿分别进行一次数据传输**，从而实现**双倍数据传输速率**   
- 在DDR SDRAM 之后，又陆续出现了DDR2、DDR3、DDR4,其内部预取分别是4路、8路、16路，即同一个时钟周期可传输4、8、16个数据，可理解成：每个时钟周期传输两次数据，每次传输2个、4个、8个数据   
  - 这就需要**提高数据总线频率**来实现高速的数据传输，DDR2的数据总线频率是DRAM工作频率的2倍，DDR3则为4倍，DDR4为8倍  

> **举例**  
> 以内存规格 $DDR4一3200$ 为例    
> $3200$ 为**等效传输频率** $f$ (单位为 $MHz$ )    
> 数据位宽 $w=8B(64b)$    
> 内存带宽（传输率）$=f×w=(3200×10^6)×8=25.6GB/s$     
> 由于时钟上升沿和下降沿各完成一次数据传输，因此数据总线频率 $=3200MHz÷2=1600MHz$  

![图 41](../../images/b06dc8ebb338f97753a9d360dad173739c67645884779e2965477ad3dd6e40c3.png)  


# 只读存储器ROM简介
**只能**从其**读出**信息、而**不能**向其**随意写入**信息的存储器，称为只读存储器 $(Read-only\   Memory,ROM)$
- 通过特定方式将信息写入**ROM**后，信息就固定在ROM中，即使电源**断电**，所保存的**信息也不会丢失**，也就是说，ROM**属于非易失性存储器**  

按照制造工艺的不同，ROM可分为：
- **掩膜式**只读存储器 $(Mask\    ROM,MROM)$    
- **可编程**只读存储器 $(Programmable\    ROM,PROM)$   
- **可擦除可编程**只读存储器 $(Erasable\    Programmable\    ROM,EPROM)$  
- **电可擦除可编程**只读存储器 $(Electrically\    Erasable\    Programmable\    ROM,EEPROM或E2PROM)$  
- **闪存** $(Flash\    Memory)$  


![图 42](../../images/dfd96c9eefbafd53758f50d9a2e0d2cd5258b17095310e6c55bae5783ffefc75.png)  

**PC用到的半导体存储器**
![图 43](../../images/85c9afd6970dd27afe31ea063abfc38f38cc2e72e4200e89d66decd6280e6dc0.png)  

**作用**
![图 44](../../images/a6fcab04a3eaef2cbab21980d24ffe231b1aabf9c259e6d90b5d932d9c381e51.png)  

# 主存的扩展及其与CPU的连接
## 位扩展
> **当存储芯片的数据总线位宽小于CPU数据总线位宽时**，采用位扩展的方式进行扩展,又称为**数据总线扩展**或**字长**扩展  

**[举例]** CPU的数据总线位宽为32位，SRAM存储芯片的数据总线位宽为1位、容量为256K×1位，采用位扩展将32片这种SRAM存储芯片组成256K×32位的存储器并与CPU连接  

![图 47](../../images/5ef17d50294928ae8c30bc4a8eeb540e6ec27771a4e833a54bd9ff480d781626.png)  



> [!cite]- [访问过程](https://www.bilibili.com/video/BV1Hn4y1X7vn?t=188.0&p=57)
> ![图 45](../../images/af840858816d41a31cf4b69b1e55a3ac02ab9c6a53c674f6a8da33fef8b42ba3.png)  

## 字扩展
> 当**存储芯片的存储容量不能满足存储器对存储容量的需求时**，采用字扩展的方式进行扩展  

**[举例]** CPU的数据总线位宽为8位，地址总线位宽为21位，SRAM存储芯片的数据总线位宽为8位、容量为256K×8位，采用字扩展将8片这种SRAM存储芯片组成2M×8位的存储器并与CPU连接  

![图 46](../../images/8591b39400b6bad311e9490e0ba417952b69225c3e8504336c05214d31a9e0bb.png)  

> [!cite]- [访问过程](https://www.bilibili.com/video/BV1pw4m1a7gx?t=186.9&p=58) 
> ![图 48](../../images/0e65f6033f537721fe7fab403780dff5d66310e1221ca3ca5c41ddeed38792d5.png)  

#### 地址空间分配
![图 49](../../images/0039aee9f6cd0975082ff6f4463867b82facc6b3a990c8527a51781ca9f818d1.png)  

## 字位同时扩展
> 当存储芯片的**数据位宽和存储容量均不能满足**存储器的数据位宽和存储总容量要求时，采用字位同时扩展    
> 先通过**位扩展**满足数据位宽的要求  
> 再通过**字扩展**满足存储总容量的要求  


**[举例]** CPU的数据总线位宽为32位，地址总线位宽为21位，SRAM存储芯片的数据总线位宽为8位、容量为256K×8位，采用字位同时扩展将32片这种SRAM存储芯片组成2M×32位的存储器并与CPU连接
![图 50](../../images/0d645a34f3cc0815059b4ccfca74d422fe68734de3d10032c42f222b29627e12.png)  

**连接**
![图 51](../../images/42cbc3999d527da9364be6e19331c81d54bd56daa64f494bc7ad2be1ca5f9446.png)  


# 主存系统的优化
## 双端口存储器
- 随着计算机技术的发展，**主存的存取速度已经成为提升计算机系统性能的瓶颈**  
- 因此，如何提高主存的存取速度，以缓解主存与CPU速度不匹配的问题，是值得研究的  
- **提高主存的存取速度**的方法有：
  - 使用高速元件来提高主存的访问速度   
  - 通过存储器的**并行工作**来提高主存的访问速度   
    - 双端口存储器  
    - 单体多字存储器  
    - 多体交叉存储器

**地址不相同**  
并行读写
![图 52](../../images/3ee05a6450dc80a06603f4bb50847cee836de36bdf7737999445ad2ffb1c4e0f.png)  

**地址相同**  
盲标志 $\overline{BUSY}$ 
![图 53](../../images/7c7a0367f68b9d0b39b640a294a8621b9f8baf7c9877c85747e548686439702d.png)  
- 当冲突发生时，由判断逻辑决定哪个端口**优先**进行读写操作，而将另一个端口的 $\overline{BUSY}$ 信号输出低电平，以**延迟**该端口对存储器的访问。高优先端口读写操作完成后，被延迟端口的 $\overline{BUSY}$ 信号输出高电平后，该端口就可以对存储器进行访问了  
- 由于**冲突访问是不可避免**的，因此双端口存储器的**访问速度不可能提高1倍**  
- 双端口存储器广泛应用于数字信号处理、图像处理、网络通信、实时控制系统医学影像处理以及人工智能等领域，以其高速并行读写能力**显著提升数据处理效率和系统性能**，但**PC中的内存并未使用**  

## 单体多字存储器
> 双通道内存技术（联动模式）

![图 54](../../images/dbceff675745376a815bcaf32fcef15498c024a59acf877fa0674645c6b41368.png)  

- 单体多字存储器的构建与存储器**位扩展**方式完全相同  
  - 多个存储模块**共享地址总线**    
  - 按同一地址**并行访问不同存储模块的同一单元**  
- 实现了**同一个存取周期内访问多个存储字**  
  - 若n个存储模块并发工作，则主存带宽提升n倍  
- 常见的多通道内存技术(双通道、三通道、四通道等)采用的就是单体多字技术  
- 两个内存条的**容量、频率时序需要完全一致**  

> 双通道内存技术（非联动模式）

![图 55](../../images/4416b80328cf35a503c1455a29e0cf8db2f1fdf7aa3e9fed821022cab6bf769a.png)  
- **内存控制器有两套独立的端口**分别连接两个内存条  
- 两个内存条也可**并发工作**，但它们的**地址、读写命令不需要同步**  
- 该模式灵活性更高，但控制更复杂  
- 两个内存条只要**频率相同**即可    

## 多体交叉存储器
多体交叉存储器也**由多个存储模块构成，这些模块的容量和存取速度相同**  
根据对**多个模块编址方式的不同**，又分为以下两种：  
- 高位多体交叉
- 低位多体交叉
#### 高位多体交叉
> 顺序编址模式 

![图 57](../../images/b229934169776079e23384909e9b0f559e9e8d5040542a614245d35c48473c4b.png)  
- 程序具有**局部性**和**连续性**的特点  
- 采用高位多体交叉（顺序编址模式）程序的**指令**和**数据**基本**分布在同一个主存模块**（存储体）中  
- 这样就会导致在程序执行过程中，同一个主存模块被频繁访问，而其他主存模块基本处于空闲状态，**无法实现多个主存模块的并行工作**  
- 高位多体交叉方式的主要目的是扩充存储器的容量，与存储器字扩展完全相同  

#### 低位多体交叉

> 交叉编址模式

![图 58](../../images/a54a6563f4928922066f6d8d6b453af5ba023f6a9813e9e4678cf5118ba380a8.png)  

- **为提高顺序访问时各存储模块的并行性**，低位多体交叉（交叉编址模式）中各存储模块均**有独立的**地址寄存器、数据寄存器和读写控制电路  
- 顺序访问时，各存储模块一般按**流水线**的方式轮流存取  



**假设**要顶序存取地址 $01100、01101、01110、01111$ 中的内容  
设各存储模块的存储周期（存取周期）为 $T$  
设其他延迟（例如总线传输周期）总和为 $τ$   
设交叉模块数量为 $m$ (一般为 $2$ 的整数次幂，本例中为 $m=4$ )  
要实现流水线方式存取，应满足条件  $T=m×τ$  

![图 59](../../images/38df62851a0238018b4696bd9bbdffcb9ece02b670f5b5eeacaf023de8eb6905.png)  

- 在 $1$ 次流水线存取过程中，所有存储模块(本例中 $m=4$ )都被访问 $1$ 次（不能重复访问某一个存储模块）  
-  $1$ 次流水线存取过程总耗时为 $T+(m-1)τ$  
- **连续n次流水线存取过程总耗时为** $nT+(m-1)τ$ 
- 可从**任意地址**（某个模块的某个存储单元）开始顺序存取  

# 高速缓冲存储器cache
## 相关基本概念
#### cache的作用   
- 主存一般采用容量大、功耗较小、成本较低的同步动态随机存取存储器SDRAM(目前主流为DDR4或DDR5)  
- 静态随机存取存储器SRAM的容量小、功耗大、成本高，但SRAM的访问速度远高于SDRAM    
- 因此，为了**提升CPU访问主存的性能**，通常会**在CPU与主存之间添加一个SRAM作为高速缓冲存储器cache**    
  - 将主存中**经常访问**或**即将访问**的数据，复制一份 **（调度）到cachet** 中，使得**大部分数据访问都可以在cachet中进行**，从而提升系统性能    
  - 采用这种方法的主要原因是CPU执行的程序具有较强的**程序局部性**   
![图 60](../../images/7166e7809f765c9712890b3ddafefe1152b54a94c73383c0b27b646017d80882.png)  


#### 程序局部性  
- 程序局部性是指，**在一段时间内，整个程序的执行仅限于一个较小的局部范围内**。具体来说，程序的局部性又表现为以下两种：  
  - **时间局部性**：若程序在某个时刻访问了**一个存储位置**，该位置在**未来可能会被多次访问**   
    - 例如程序中的**循环**结构和调用过程就很好地体现了时间局部性  
  - **空间局部性**： 若程序访问了**某个存储位置**，则**其附近的存储位置也可能被访问**   
    - 例如程序中的**数组、结构体成员、顺序执行的代码块**，通常在主存中是按顺序存放的，对它们的访问，就具有较强的空间局部性  
    > [!example]- 举例  
	> ![图 61](../../images/499e56ce318b25bf93f3c2fbeebf8deef3aaf3d1d7f3bc05d118e2f533858f19.png)  

#### cache系统的性能评价  
- 在 $CPU$ 和主存之间添加了 $cache$ 后， $CPU$ 不再直接访问慢速的主存，而是通过字节地址访问快速的 $cache$   


![图 62](../../images/47305c6ccbe1004ce52358df1562ccbdf765a8dfe8b9f036b67489bede9ef2c3.png)  
上述情况下，数据访问时间称为**命中访问时间**，记为 $t_c\begin{cases}\   cache内的查找时间\\ \   cache访问时间\end{cases}$


![图 63](../../images/5d632b484ec1753d70888bc29371d3c02eedbd1101af9c2cfaf859461d477c9a.png)  
上述情况下，数据访问时间称为**缺失补偿** $(Miss Penalty)\begin{cases}\   cache内的查找时间\\ \    主存访问时间（较为漫长），记为t_m \\ \   cache访问时间\end{cases}$  
通常使用 $t_m$ 表示缺失补偿


- 为了便于快速查找，主存和 $cache$ 都被划分成若干个固定大小的**数据块(Block),每个数据块又包含若干个字**  
  - 若进行数据访问时**出现数据缺失**的情况，则需要**将缺失数据所在的数据块从慢速主存载入cache中**   
  - 因此，**缺失数据相邻的数据**也会随着数据块一起载入cache  ![图 64](../../images/f80ec1883ef9e0eeacfb1cab051306d33fad239fcfad1e729c71917e3b2eb906.png)  
- 上述**预读策略**可以充分利用程序的**空间局部性**，提高顺序访问的**命中率**  
- 然而，**数据块的大小**对 $cache$ 有较大影响：  
  - 数据块过小：无法利用预读策略优化程序的空间局部性   
  - 数据块过大：将使得替换算法无法充分利用程序的时间局部性   
- 进行数据分块后，需要给主存内的数据块和cachep内的数据块分配地址  
  - **数据块的地址**由**块地址**和**块内偏移地址**(简称块内偏移 $\mathrm{Offset}$ )两部分构成    
  - 由于cache容量比主存容量小很多，因此cache内的块地址长度小于主存内的块地址长度  ![图 65](../../images/6d1f2b0e43e4af791b7ea65b723838540fcba581999a41e82e7f0e85ef05d2c3.png)  

**真正的评价标准**
- 某程序运行期间命中 $cache$ 的次数记为 $n_c$ ,从主存中访问信息的次数记为 $n_m$ ,**命中率** $(Hit\    Ratio)$ 记为 $h$ : $$h=\frac{n_c}{n_c+n_m}$$  
  - $h$ 越接近于 $1$ 性能越好  
- $1-h$ 称为**缺失率** $(Miss\   Ratio)$ 。命中情况下的访问时间记为 $t_c$ ,数据缺失情况下的访问时间记为 $t_m$ , $cache$ /主存系统的**平均访问时间**记为 $t_a$ :  $$t_a=ht_c+(1-h)t_m$$  
  -  $h$ 越接近于 $1$ , $t_a$ 越接近于 $t_c$ 
- 访问效率记为 $e$ : $$e=\frac{t_c}{t_a}=\frac{t_c}{ht_c+(1-h)t_m}=\frac{1}{h+(1-h)\frac{t_m}{t_c}}\frac{1}{h+(1-h)r}$$
  -  $h$ 越接近于 $1$ , $e$ 越接近于 $1$  
  - $r$ 一般为 $5\sim 10$ ，不能太大

## cache的读、写流程
#### 读  
**流程图**  
![图 66](../../images/b04c900a061dc8240b6e40cd4fb3664d17aa37249fbd8231338899b1b28295fe.png)  
- 读命中访问时间最短   
- 构建cache系统时，应尽可能**提高命中率**，以提升读操作性能  
  - 通过较好的**替换策略**，将经常访问的**热数据保留**在cachel中，将不经常访问的**冷数据淘汰**，来充分**利用时间局部性**，以提高命中率   
  - 数据缺失时，会将缺失数据所在数据块中的其他数据一起载入，这种**预读策略**可以充分**利用空间局部性**来提高**顺序访问**的命中率  

#### 写  
**流程图**  
![图 71](../../images/8a472c702a3be596c7f0aef9c607b962dbbfe7dc1e985b4e1e42a337c3743458.png)  

**写回**
![图 67](../../images/98076340376d78238a8f2b1232773cd1b046305f9b0b402e4f737bb4217a0a36.png)  
**写穿**
![图 68](../../images/c61373029c0df541841fbeebcf63814f6abd9d7fc3828a4f1f610c00487a5f44.png)  
**非写分配**
![图 69](../../images/894daf4cb561f50cc7d45cf5b45d06efe14247f9a424eab060ac92ec882223ff.png)  
**写分配**
![图 70](../../images/1e4813e4198d4b05b5c932e944ba900f0dfc9824cbda7828fc247b1950bed5c1.png)  

- 采用**写回策略**时，将数据写入cachel即可返回写响应时间最短  
  - 对于**突发的小数据量写入**，cache能明显提高写入性能  
  - 然而，由于cache容量很小，当**cache写满数据后**，需要将cacher中的脏数据淘汰，这就需要先将脏数据迁移到主存中，然后从主存载入新数据块到cachel后才能向cache写入新数据，该过程的**写性能比没有采用cache的主存还要慢**  

## 地址映射
- 将主存划分成若干个等长的数据块 $(bock)$  
- 将cache划分成若干个等长的区域，称为行 $(line)$ 或槽 $(slot)$  
- $cache$ 保存 $mn$ 个数据块中的 $n$ 个  
- 在系统启动或复位时，每个 $cache$ 行都是空的（其中的信息无效），只有载入了主存中的数据块后信息才有效  
- 为了表明 $cache$ 行中的信息是否有效，每个 $cache$ 行需要一个有效位 $(valid\    bit)$  
- 将有效位清零，可以淘汰某 $cache$ 行中的数据块，称为**冲刷** $(flush)$   
- 载入一个新的数据块后，再将有效位置 $1$    
- 载入主存数据块时还需要记录一些相关信息：  
  - 主存数据块地址标记(用于地址映射)  
  - 脏数据标志位(用于写入策略)  
  - 淘汰计数(用于替换策略)  


![图 72](../../images/4d3db3fff3607fb1da91e4467bb3018b9cafc5d985123e9d45e67a894abde4a1.png)  

- 将某个主存数据块载入 $cache$ 行时，它们之间应该采用某种**映射规则**   
- 这样， $CPU$ 要访问主存中的某个信息时，可依据映射规则到 $cache$ 对应行中查找信息，而不用在整个 $cache$ 中查找  

#### 直接映射
> (Direct Mapping)

- 直接映射规则：每个主存数据块映射到 $cache$ 中的一个固定行 
-  $cache$ 行号=主存数据块号$\quad mod\quad   cache$ 行数
- 等效于将主存按照 $cache$ 大小进行了分区  
  - 每个分区包含的数据块的数量与 $cache$ 的行数相同  
  <!-- - 查找数据时：  ![图 74](../../images/9bc8cb931c04057381c23edbb12385583704969b7b74ba401dd7b9ddcceac1ce.png)   -->
![图 73](../../images/709170cfeea3c28f17b2f26caa91e28435dfc73496416d65975363a71d511546.png)  


**信息的主存地址**
![图 75](../../images/71e36331487594eeb0dbf43b7d04595cebbd042a5c801475e511d8fbcf4732e3.png)  

**CPU读取主存信息**
![图 76](../../images/a6df9a03186e30543c90a15792c6c88475514e9b0fe50f0f82e7bdceaaf19823.png)  
- CPU要读取主存中的某个信息，通过该信息的主存地址的区内数据块号(cache行号)直接索引到对应的cache行  
  - 若cache行中保存的主存分区号与信息的主存地址中的**主存分区号相同且有效位为1（即有效）**时，则**数据命中**。此时，根据信息的主存地址中的数据块内偏移，从该cache行中的数据块副本中读取信息  
  - 若cache行中保存的主存分区号与信息的主存地址中的**主存分区号不同或有效位为0（即无效）时**，则**数据缺失**。此时，CPU根据该信息的主存地址，将主存中该信息所在数据块载入相应cache行，相应地，还要将该cache行的有效位置1，以及将该cache:行的主存分区号设置为该信息的主存地址中的主存分区号，同时将信息送入CPU  


**硬件逻辑实现**
![图 77](../../images/ef1252d0e450a5aa8b2a2d701b3575d694e3badb5f152ba733da27d3901310a2.png)  

[流眼泪了](https://www.bilibili.com/video/BV1RS411A7U6?t=911.0)

> [!danger] 特点：
> 每个主存数据块映射到cache中的一个固定行  
> - **利用率低**   
> - **命中率低**   
> - **冲突率高** (未满也可能发生数据块替换)   
> 
> 对于快速查找的硬件实现， **成本较低**（仅需要译码器和一个比较器，而不像全相联映射需要相联存储器来实现），**适合于大容量cache使用**  
>  
> **替换算法较为简单**，如果访问不命中则直接替换相应cache行即可。但是，若该cache行存在脏数据，则需要将脏数据写入二级存储器以保证数据一致性


#### 全相联映射
> (Full Associative Mapping)

- 全相联映射规则：每个主存数据块都可映射到cachel中的任何一个cache行  
  - 新的主存数据块可以载入到cacher中的任何一个空行   
  - 只有cache满时，才需要进行数据块替换  ![图 79](../../images/669324599cd3a28484adbb33e6e592c70b723aa7545675d5f5d9d73037d38ab4.png)  

**描述主存中某个信息的位置**
![图 80](../../images/34bdc0997aa1144d9f88f0934a49a4bf4790f7e31a6794bffc2fbc7e3b8b1c04.png)  

**根据信息的主存地址在cache中快速查找**    
- 直接将主存数据块地址与所有cache行中的主存数据块地址进行**并发比较**：所有cache行中有效位的值与1进行并发比较  
  - 若读命中，则输出相应cache行数据块副本中块内偏移处的信息  
  - 若写命中，则写入数据，同时将脏数据标志位置1  ![图 81](../../images/ce97a7eb587abfade5d95e7cdcc0b92afd16ba7668a82eae2a8ade133ba343dd.png)  

**硬件逻辑实现**
![图 82](../../images/d7c2f1b0e0f7c8ce7eeed20015c928007527db700a95dc779b6e0da2385599b7.png)  
[流眼泪了](https://www.bilibili.com/video/BV1JE421P7Lw?t=292.0)


> [!danger] 特点：  
> 每个主存数据块都可映射到cacher中的任何一个cache行  
> - **利用率高**  
> - **冲突率低**(只要cache中还有空行就不会发生数据块替换)  
> 
> 查找时需要并发比较所有cache:行中的主存数据块地址，每个cache行对应一个比较电路，**硬件成本高**，**时间开销较大**，只适合于**小容量cache**使用    
> 
> **cache满后**，当载入新主存数据块时，需要利用替换算法进行替换，**替换策略和算法较为复杂**  

#### 组相联映射
> (Set Associative Mapping)

- 组相联映射规则  
  1.  将cacher中的所有行划分成固定大小的组，每组包含k行，称为**k路组相联**   
  2.  主存数据块采用**直接映射**方式对应到cache中固定的**组**  $$cache组号=主存数据块号\quad mod\quad  cache组数量$$  
      - 等效于将主存数据块按cache组的数量进行了分区  
      - 每个分区中包含的数据块的数量与cache组的数量相同  
      - 每个分区中的数据块，各自对应某个固定的cache组  
  3.  主存数据块在所对应的组内，采用**全相联映射**，可对应到**组内**任何一个**cache行**  ![图 86](../../images/233de91ae139948bfed437626dc4b1c4dc2b038b6557cccc30e291b92f4476c2.png) 
<!-- ![图 83](../../images/c485ab5783cfbc1cd8a79d0da438b270a4ed358254f0d73a7eb709c971f4d86d.png)   -->

<!-- ![图 84](../../images/37e62dcd4c73a6634c0f13c2069318c22130a0db64daf0024cb39e20a41d4fa9.png)   -->

 


<!-- ![图 85](../../images/1bd1b0fee2b09a105e44484ec8da6a40ad558734df71cf6d7a1fbe09f4572fba.png)   -->
**描述主存中某个信息的位置**
![图 87](../../images/01a078a439c6b78b39b72f8097eb48413d1f19a53b2643272d71ed2bb928bb5f.png)  

 

**根据信息的主存地址在cache进行快速查找**   
- 首先基于信息的主存地址的区内块号(组索引 index)索引到相应的cache组  
- 之后，将信息的主存地址的主存分区号部分与所选cache组内所有行的标记tag、1与所选cache组内所有行的有效位，进行全相联并发比较，如果匹配，则数据命中，否则数据缺失  ![图 88](../../images/e168583412c76cb0b85b3c44c65398b7010b3f7ecd58477e978da128b7ed88c1.png) 

**对比**  
- 与全相联映射相比，组相联映射将全相联并发比较限制在了单个cache组内，而不是整个cache  
- 因此，组相联映射进行全相联并发比较时所需的比较器路数，是单个cache组内cache行的数量(本例为2)而不是整个cache中cache行的数量(本例为2n)，极大降低了硬件开销  

> [! danger] 若整个cache划分为1个组 $\Rightarrow$ 转变成了全相联映射</p>若每个cache组只包含1个cache行  $\Rightarrow$ 转变成了直接映射


**硬件逻辑实现**
![图 89](../../images/ff3e3153e5be0af6f38c27153eadd295dbfb58cac69305382561fa55099b69b6.png)  
[流眼泪了](https://www.bilibili.com/video/BV1Rb421E7SU?t=754.7)

> [!danger] 特点：  
> **cache组所包含cache行的数量(记为 $G_r$ )**，决定了数据块**冲突的概率**和**全相联并发比较的复杂性**  
> -  $G_r$ 越大，则发生数据块**冲突的概率越低**，但**全相联并发比较电路越复杂**  
> - **选取适当的** $G_r$ ,可使组相联映射的硬件开销比全相联映射的**硬件开销低很多**，而**性能上仍可接近**全相联方式  
> - 早期cache容量不大，通常 $G_r$ =2或4，即2路或4路组相联比较常用。随着技术的发展，cache容量不断增大， $G_r$ 的值也随之增大，目前很多处理器的cache采用8路或16路组相联  

#### 三种地址映射方式的比较
- 一个主存数据块对应的cache行的数量，称为 **“关联度”**  
  - 直接映射方式的**关联度为1**  
  - 全相联映射方式的**关联度为cache的总行数**  
  - k路组相联映射方式的**关联度为k**  
- **关联度**与**命中率**、**命中时间**、cache行中**标记tag**所占空间（额外开销）的关系如下  
  - 前提条件：cache容量相同、主存数据块大小相同  
  - 关联度越低，命中率越低。因此，**直接映射方式的命中率最低，全相联映射方式的命中率最高**  
  - 关联度越低，判断是否命中的开销越小，命中时间越短。因此，**直接映射方式的命中时间最短，全相联映射的命中时间最长**  
  - 关联度越低，cache行中标记tag所占空间（额外开销）越少。因此，**直接映射方式的额外空间开销最少，全相联映射方式的额外空间开销最大**

![图 90](../../images/fe1a404f9fda3bb4396b242f42123b0c800cd84b844e64ea6fd99cdf1502417a.png)  

## 替换算法

- **先进先出算法**
![图 91](../../images/b9e0dcba4074f30ea90bebcb6ceb363fa9c3045a931d44ee621251f0f1ef7f69.png)  
- **最不经常使用算法**
![图 92](../../images/09a7c9047571db645d5a0f7213c4aa8a73cb94177b98e9be022f3fdf78abbeba.png)  
- **近期最少使用算法**
![图 93](../../images/2bd147f2d11eeaf9d89c6aaa2a566d381176609f7ea42d1e940cfd750109eb9f.png) 
![图 95](../../images/5e1ca595a4cdf45c7ecc05cd18de048f22dbe14a433b0def6a3fad207a0fffe3.png)  
![图 96](../../images/4e7e6ff8bb460718376e0f1bed0add36ce2a6dcbc08a175010e70a0f79a811d0.png)  
![图 98](../../images/335e04bb6059e5dfed0f8042c21659c4ed4540e2fef25fa640123587cee8fd81.png)  
- **随机替换**
## 写入策略
![图 99](../../images/99ad8a462054b749cc1cdd5143cc39d9906818224e4f759775a488836ee85d15.png)  

## 分类和应用



# 虚拟存储器
- 主存的容量受限（一般远小于外存），且不同计算机所配置的**主存容量也不完全相同**  
  - **程序员**在设计程序时，**不**希望受到不同计算机的**不同主存容量限制**，这是一个需要解决的问题  
- 现代操作系统往往都是**多任务操作系统**，在计算机系统中**同时有多个用户程序的进程运行**  
  - 让更**多个程序**（容量甚至大于主存容量）**的进程**在容量受限的主存中有效而安全地**并发执行而不相互干扰**，这是另一个需要解决的问题  
- 为了解决上述两个问题，**虚拟存储器技术**应运而生。目前，几乎所有的计算机中都采用了虚拟存储器技术

![图 100](../../images/be87b1a16e73712e50fb80edf2ac4b73a4265a79b5bc72f13c7e0beffd1dc568.png)  

- 可将**虚拟存储器**看作是主存和辅存构成的、单一的、可供CPU直接访问的超大容量主存  
  - 程序员在进行编程时，面向的是虚拟存储器，相应地，使用的是**虚拟地址VA**  
- 为了实现虚拟存储器，需要增加相应的软硬件：  
  - 软件：**操作系统OS**  
  - 硬件：**存储器管理单元MMU**  
  1. CPU通过MMU将指令中的**虚拟地址VA**转换为主存的**物理地址PA**  
  2. 在地址转换过程中，MMU会检查是否发生了数据缺失（即访问信息不在主存）或地址越界、访问越权或越级等存储保护错误  
     - 若**数据缺失**，则由操作系统将数据从辅存调入到主存  
     - 若出现**存储保护错误**，则由操作系统进行相应的异常处理
- 虚拟存储器利用程序的**局部性原理**，从辅存调入程序到主存时，**并不是将程序的全部代码和相关数据调入主存**，通常只需要加载很小一部分即可，以提高主存的利用率  
  - 这与**cache技术类似**，尽可能将辅存中经常被访问的程序和相关数据的副本调入到主存中。当**主存满**时，需要将主存中最不经常访问的程序和相关数据进行**淘汰**  

## 页式虚拟存储器
#### 概述
- 可将虚拟存储器看作是主存和辅存构成的、单一的、可供CPU直接访问的超大容量主存  
- 对于页式虚拟存储器，其地址空间被划分成若干个固定大小的页面(page),简称页，主存与辅存之间按页交换信息  
  - 虚拟地址空间中的页称为虚拟页 $(Virtual\   Page,VP)$ ，简称虚页，也称为逻辑页  
  - 主存空间中的页称为物理页 $(Physical\   Page,PP)$ ，简称实页，也称为页框（页帧）![图 102](../../images/44b2d4426734a8e6a363088d57cf196cc4dcbedfb848f88b99ab4c11f765b6aa.png)  

- 页式虚拟存储器采用“请求分页”的思想：  
  - 将进程中活跃的页面（包含有当前访问的指令或数据）从辅存调入主存，而不活跃的页面保留在辅存中  
  - 当访问某个信息（指令或数据）时，若该信息所在页面不在主存中时发生缺页异常，此时从辅存将缺失页面调入主存

![图 103](../../images/594a8449e775ee6513b154168435361d9fdff4a836fcfccca21142deed21aa32.png)  

- 综上所述，页式虚拟存储器的**缺页处理代价远大于cach数据缺失（未命中）的处理代价**。因此，通常将页式虚拟存储器中主存与辅存之间交换的**页面的大小设置得比较大**，常见的**页面大小为4KB**，也有更大容量的页面  
- 由于缺页处理的代价较大，因此，主存与辅存之间采用**全相联映射方式**，以提高命中率   
- 由于辅存的访问速度远小于主存的访问速度，因此在进行写操作时，应采取的写入策略为**写回法**，而不是写穿法


#### 地址映射和页表
- 页式虚拟存储器采用**全相联映射**    
  - **每个虚拟页可以存放到主存中的任何一个空闲的物理页**    
- 对于**每个进程**，都需要建立进程中**各个虚拟页**与所存放的**主存物理页**或**磁盘上存储位置**之间的关系，通常采用**页表** $(Page\   Table,PT)$ 来记录这种对应关系    
![图 105](../../images/567bf7d4df5b4763a4e8d9ff748929d4eac3cd57abfb122142a038eeec9407fe.png)  
- 有效位  
  - 有效位=1，表明该虚拟页已从辅存调入主存  
  - 有效位=0，表明该虚拟页没有被调入主存  
  - 若存放位置=nul,表明该虚拟页为没有内容的页面  
  - 若存放位置≠L,存放位置给出了该虚拟页在磁盘上的起始地址
- 脏位  
  - 用来指明页面是否被修改过  
  - 由于虚拟存储器采用写回法，因此，在需要进行页面替换时，可根据脏位来判断是否需要将主存中被替换的页面写回辅存  
  - 磁盘的交换分区用于存放主存中替换出的动态修改数据的页面
- 替换控制位  
  - 用来指明页面的使用情况，需要配合具体的替换策略来设置：  
    - FIFO位  
    - LRU位  
- 访问权限位   
  - 用来指明页面的访问权限（用于存储保护）  
    - 可读可写  
    - 只读  
    - 只可执行
- 禁止缓存位
  - 用来指明页面是否可以载入cache  
  - 正确设置该位以确保辅存、主存和cache的数据一致性

**地址转换**
![图 106](../../images/9ec9575484209244d6fc71fcf0dbcb8ed299df5c927d5adc21fe67cc9475c3c8.png)  
- 对于采用虚拟存储器的系统，**指令中给出的地址是虚拟地址**
- 因此，CPU执行指令时，首先由CPU内部的**MMU将虚拟地址转换为主存的物理地址**，然后才能到主存取指令和数据
- 页表属于进程控制信息，存放在进程地址空间的内核区中  
- 每个进程都有一张常驻于主存的页表，**页表基址寄存器PTBR**用于记录**页表**在主存中的**首地址**  
  - 进行**进程切换**时，只需要简单地**切换PTBR**的值，就可以实现**页表的快速切换**  

#### 访问流程
**页面命中**
![图 107](../../images/b79a6dee23fa5b6924dd9822e0e3592c2bae56155e49cc66a141117c35c4b35f.png)  

1. CPU给出一个**虚拟地址**，由**MMU**负责对该虚拟地址进行转换   
2.  MMU利用**页表基址寄存器PTBR**和该虚拟地址中的**虚拟页号**部分生成**页表项地址**，通过页表项地址访问主存中的相应**页表项**  
3.  主存给MMU返回页表项   
4.  若页表项中 **“有效位”为1**，则表明该页表项所对应的**虚拟页已**从辅存**调入主存**、页表项中“存放位置”字段存放的是**物理页号**，用物理页号与虚拟地址中**页内偏移**部分构造出**物理地址**，通过物理地址访问主存中的相应数据   
5.  主存给CPU返回数据  


**页面缺失**
![图 108](../../images/0b7c22f2026e8cafb7b93b75d2730577621d5819896471572d749fffec73374f.png)  
1. CPU给出一个**虚拟地址**，由**MMU**负责对该虚拟地址进行转换  
2. MMU利用**页表基址寄存器PTBR**和该虚拟地址中的**虚拟页号**部分生成**页表项地址**，通过页表项地址访问主存中的相应**页表项**  
3. 主存给MMU返回页表项  
4. 页表项中的 **“有效位”为0** ，则表明所访问的**页不在主存中**，MMU触发一次异常，调用操作系统内核中的**缺页异常处理程序**进行处理  
5. 若主存中相应的**页表已满**，则需要根据**替换算法**确定哪个页面被替换。如果该页面的**脏位为1**，则把该**页面调出到磁盘**，否则直接丢弃  
6. 缺页处理程序**从磁盘调入新的页面到主存**，并**更新页表中相应的页表项**  
7. 缺页处理程序**返回到原来的进程**，该进程中**之前引起缺页的指令会重新启动**，这次执行就不会缺页了，按之前介绍的页面命中情况的步骤 $2\sim 5$ 执行

**结合cache**
![图 109](../../images/a6cfbb23c29ab3a923948edc7b8e326d8819ebf03e0b53f2fbbe5902602cac38.png)  
![图 110](../../images/1c3d9c957fcbca3d233364a0664b4afb801ee2ed5017625bfe797af56f526e5a.png)  

#### 使用快表TLB加速地址转换
- 为了加快MMU进行虚拟地址到物理地址转换的速度，现代处理器内部都包含有一个**转换后备缓冲器** $(Translation\   Lookaside\    Buffer,TLB)$ ,专门用于**缓存经常访问的页表项**  
- 可将TLB看作是一个容量较小的cache（只不过**仅用于缓存**经常访问的**页表项**），由于TLB的访问速度远高于主存，因此通常将TLB表称为**快表**，相应地将主存中的页表称为**慢表**  
  - 为了提高查找速度，TLB一般采用**全相联**或**组相联**方式，出现TLB缺失时常采用**随机替换算法**  ![图 111](../../images/0f6951ca5ce08c09d44dd7862302e4048dcc7826bf361ef4f438829d95fefe19.png) 
    - ~ 全相联 ![图 112](../../images/998aed9bd4f9be92b4369b7dd2702bd6834aaab5fc389d97a730c2efa39b6fe6.png) 
    - ~ 组相联 ![图 113](../../images/87a5f3e3b9d77643f1225eec9ca4eaf035c9b042143b5d79ebac32c53d30104b.png)  

**基于快表TLB的访问过程**
![图 114](../../images/bd5ef29174fc920cf13b7506bf032b159ea167af6cc9b9e5707cc4402be707a0.png)  


#### 基于TLB、cache的访存流程
- 现代计算机一般都会采用虚拟存储器技术，**虚拟存储器**需要**硬件**(MMU、TLB等)和**操作系统协同工作**  
  1. 在**操作系统引导完成之前**，CPU**使用物理地址访问主存**，此时为**实地址模式**（简称实模式）  
  2. 在**操作系统引导完成之后**，进入**保护模式**（或称虚地址模式），此时CPU**使用虚拟地址访问主存**  

![图 115](../../images/c8dd833813d5c09979cd120ccf4843fbe8d2c9dd10ebe2746f76dcc3611070cb.png)  
![图 117](../../images/d7c4fe0cfc51484e9da8e14cf4511d953a54b9308ceb60882ec528dfddf15e69.png)  

- **cache缺失处理**由**硬件完成**    
- **缺页处理**由**操作系统**通过**缺页异常处理程序**来完成，即由**软件**完成  
- TLB缺失处理，既可以用硬件也可以用软件来完成。若用软件完成，则操作系统通过专门的**TLB缺失异常处理程序**来完成
